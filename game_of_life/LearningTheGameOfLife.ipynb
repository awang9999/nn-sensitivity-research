{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726264cb-7df7-4684-b71b-5d0a1b0b3f5e",
   "metadata": {},
   "source": [
    "# Learning The Game of Life\n",
    "\n",
    "This notebook trains a CNN to learn Conway's game of life. The CNN is defined in `GOLCNN.py` and the dataset it is trained on is generated by `GOLDataset.py`. It trains pairs of networks on the same sequence of data. Here are what the several parameters throughout the notebook mean:\n",
    "- `seed` allows you to specify a seed for any random number generators used. This ensures reproducibility of the training sequence.\n",
    "- `name1` is the name of the first CNN. Providing a name is important because the model checkpoints and logs are saved using this name.\n",
    "- `name2` is the name of the second CNN.\n",
    "- `dataset_size` specifies the number of examples provided in each training epoch. The total number of examples the models see during training is `epochs` times `dataset_size`.\n",
    "- `datapoint_size` is the size of each individual training data point. Since we are learning the game of life, each training point is a 2d array. By default, this value is 32 (indicating the data points are 32 by 32 arrays). Unfortunately, the training procedure does not seem to respond well when this value is less than 32 in practice. Hopefully this bug can be resolved.\n",
    "- `learning_rate` is the learning rate passed on to the optimizer in training the CNN.\n",
    "- `epochs` is the number of times to run the training sequence during the first training era. One epoch corresponds to `dataset_size` number of examples seen.\n",
    "- `era2epochs` is the number of times to run the training sequence during the second training era. The second training era is for fine tuning and the `learning_rate` is set to 0.1 times the original `learning_rate`.\n",
    "- `checkpoint_rate` is the interval at which we evaluate the model using the test routine and record the accuracy data. Additionally, a checkpoint of the model is saved for each interval.\n",
    "- `m` This is the overparameterization factor for the CNN defined originally by the Kenyon and Springer paper. Effectively, it is the number of times more parameters more than the minimal viable amount of parameters to learn the game of life.\n",
    "- `n` This is also a parameter of the CNN defined by the Kenyon and Springer paper. It represents the number of steps of the Game of Life the CNN attempts to simulate in one pass. \n",
    "\n",
    "Model checkpoints are saved at `./models/` and logs of epochs, loss, accuracy, etc are saved at `./logs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a064907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from GOLDataset import generateDataset\n",
    "from GOLCNN import OPNet, train_epoch, test_model\n",
    "from MinimalSolution import MinNet\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70df9be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9be5725e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed everything for reproducibility\n",
    "# seed = 11 for carl m=16, n=2\n",
    "# seed = 12 for ethan m=8, n=2\n",
    "# seed = 13 for greg m=8, n=2\n",
    "# seed = 20 for lionel and melissa m=8, n=2\n",
    "seed = 20\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b25855-8d44-44ce-8a15-460d55da34b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name1 = \"amber\"\n",
    "name2 = \"brian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbfc8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0, Test Loss: 3.1845403063913623e-18, Correct: 1000/1000, Incorrect: 0/1000\n"
     ]
    }
   ],
   "source": [
    "# Ensure test_model() works on the minimal solution CNN\n",
    "dataset_size = 1000\n",
    "dataloader = generateDataset(dataSetSize=dataset_size, size=32, n_steps=3)\n",
    "min_model = MinNet(3)\n",
    "min_model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "acc, epoch_test_loss, num_correct, num_wrong = test_model(min_model, dataloader, 1, criterion)\n",
    "print(f'Accuracy: {acc}, Test Loss: {epoch_test_loss}, Correct: {num_correct}/{dataset_size}, Incorrect: {num_wrong}/{dataset_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3241bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "dataset_size = 1000\n",
    "datapoint_size = 32\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 1500\n",
    "era2epochs = 0\n",
    "checkpoint_rate = 100\n",
    "\n",
    "m = 8 # Overparameterization Factor\n",
    "n = 2  # Steps of GOL simulation\n",
    "\n",
    "model1 = OPNet(m, n)\n",
    "model2 = OPNet(m, n)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=learning_rate)\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c51e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models loaded to device\n"
     ]
    }
   ],
   "source": [
    "model1.to(device)\n",
    "model2.to(device)\n",
    "print('models loaded to device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d195285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lionel: Epoch: 100/1500, Test Loss: 0.18643927574157715, Incorrect: 1000/1000 examples\n",
      "melissa: Epoch: 100/1500, Test Loss: 0.1789475381374359, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 200/1500, Test Loss: 0.17555750906467438, Incorrect: 1000/1000 examples\n",
      "melissa: Epoch: 200/1500, Test Loss: 0.1678985357284546, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 300/1500, Test Loss: 0.16865594685077667, Incorrect: 1000/1000 examples\n",
      "melissa: Epoch: 300/1500, Test Loss: 0.16071560978889465, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 400/1500, Test Loss: 0.16200457513332367, Incorrect: 1000/1000 examples\n",
      "melissa: Epoch: 400/1500, Test Loss: 0.15792113542556763, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 500/1500, Test Loss: 0.14897002279758453, Incorrect: 1000/1000 examples\n",
      "melissa: Epoch: 500/1500, Test Loss: 0.14863507449626923, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 600/1500, Test Loss: 0.1362263560295105, Incorrect: 1000/1000 examples\n",
      "melissa: Epoch: 600/1500, Test Loss: 0.1394142210483551, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 700/1500, Test Loss: 0.12599514424800873, Incorrect: 1000/1000 examples\n",
      "melissa: Epoch: 700/1500, Test Loss: 0.1338026076555252, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 800/1500, Test Loss: 0.10260124504566193, Incorrect: 1000/1000 examples\n",
      "melissa: Epoch: 800/1500, Test Loss: 0.11756349354982376, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 900/1500, Test Loss: 0.01796683855354786, Incorrect: 983/1000 examples\n",
      "melissa: Epoch: 900/1500, Test Loss: 0.045117516070604324, Incorrect: 1000/1000 examples\n",
      "lionel: Epoch: 1000/1500, Test Loss: 0.0018462920561432838, Incorrect: 5/1000 examples\n",
      "melissa: Epoch: 1000/1500, Test Loss: 0.0017564201261848211, Incorrect: 0/1000 examples\n",
      "lionel: Epoch: 1100/1500, Test Loss: 0.0006901100859977305, Incorrect: 1/1000 examples\n",
      "melissa: Epoch: 1100/1500, Test Loss: 0.0005448689917102456, Incorrect: 0/1000 examples\n",
      "lionel: Epoch: 1200/1500, Test Loss: 0.0003837257099803537, Incorrect: 0/1000 examples\n",
      "melissa: Epoch: 1200/1500, Test Loss: 0.00028981585637666285, Incorrect: 0/1000 examples\n",
      "lionel: Epoch: 1300/1500, Test Loss: 0.0002581588050816208, Incorrect: 0/1000 examples\n",
      "melissa: Epoch: 1300/1500, Test Loss: 0.000189920436241664, Incorrect: 0/1000 examples\n",
      "lionel: Epoch: 1400/1500, Test Loss: 0.00018923633615486324, Incorrect: 0/1000 examples\n",
      "melissa: Epoch: 1400/1500, Test Loss: 0.00013698604016099125, Incorrect: 0/1000 examples\n",
      "lionel: Epoch: 1500/1500, Test Loss: 0.00014746803208254278, Incorrect: 0/1000 examples\n",
      "melissa: Epoch: 1500/1500, Test Loss: 0.00010579129593679681, Incorrect: 0/1000 examples\n",
      "END OF ERA 1\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "full_data1 = []\n",
    "full_data2 = []\n",
    "checkpoint_data1 = []\n",
    "checkpoint_data2 = []\n",
    "\n",
    "for t in range(1, epochs + 1):\n",
    "    dataloader = generateDataset(dataSetSize=dataset_size, \n",
    "                                 size=datapoint_size, \n",
    "                                 n_steps=n)\n",
    "    \n",
    "    epoch_train_loss1 = train_epoch(model1, optimizer1, criterion1, dataloader, m)\n",
    "    full_data1.append([t, epoch_train_loss1])\n",
    "    \n",
    "    epoch_train_loss2 = train_epoch(model2, optimizer2, criterion2, dataloader, m)\n",
    "    full_data2.append([t, epoch_train_loss2])\n",
    "    \n",
    "    if t % checkpoint_rate == 0:\n",
    "        print(f'Epoch: {t}')\n",
    "        \n",
    "        acc1, epoch_test_loss1, num_correct1, num_wrong1 = test_model(model1, dataloader, m, criterion1)\n",
    "        checkpoint_name1 = f'{name1}_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data1.append([t, checkpoint_name1, acc1, epoch_test_loss1, num_correct1, num_wrong1])\n",
    "        print(f'{name1}: Epoch: {t}/{epochs}, Test Loss: {epoch_test_loss1}, Incorrect: {num_wrong1}/1000 examples')\n",
    "        torch.save(model1, f'./models/{checkpoint_name1}')\n",
    "        \n",
    "        acc2, epoch_test_loss2, num_correct2, num_wrong2 = test_model(model2, dataloader, m, criterion2)\n",
    "        checkpoint_name2 = f'{name2}_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data2.append([t, checkpoint_name2, acc2, epoch_test_loss2, num_correct2, num_wrong2])\n",
    "        print(f'{name2}: Epoch: {t}/{epochs}, Test Loss: {epoch_test_loss2}, Incorrect: {num_wrong2}/1000 examples')\n",
    "        torch.save(model2, f'./models/{checkpoint_name2}')\n",
    "        \n",
    "print(\"END OF ERA 1\")\n",
    "\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=learning_rate*0.1)\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=learning_rate*0.1)\n",
    "\n",
    "for t in range(epochs + 1, epochs+era2epochs+1):\n",
    "    dataloader = generateDataset(dataSetSize=dataset_size, \n",
    "                                 size=datapoint_size, \n",
    "                                 n_steps=n)\n",
    "    \n",
    "    epoch_train_loss1 = train_epoch(model1, optimizer1, criterion1, dataloader, m)\n",
    "    full_data1.append([t, epoch_train_loss1])\n",
    "    \n",
    "    epoch_train_loss2 = train_epoch(model2, optimizer2, criterion2, dataloader, m)\n",
    "    full_data2.append([t, epoch_train_loss2])\n",
    "    \n",
    "    if t % checkpoint_rate == 0:\n",
    "        print(f'Epoch: {t}')\n",
    "\n",
    "        acc1, epoch_test_loss1, num_correct1, num_wrong1 = test_model(model1, dataloader, m, criterion1)\n",
    "        checkpoint_name1 = f'{name1}_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data1.append([t, checkpoint_name1, acc1, epoch_test_loss1, num_correct1, num_wrong1])\n",
    "        print(f'{name1}: Epoch: {t}/{epochs+era2epochs}, Test Loss: {epoch_test_loss1}, Incorrect: {num_wrong1}/1000 examples')\n",
    "        torch.save(model1, f'./models/{checkpoint_name1}')\n",
    "        \n",
    "        acc2, epoch_test_loss2, num_correct2, num_wrong2 = test_model(model2, dataloader, m, criterion2)\n",
    "        checkpoint_name2 = f'{name2}_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data2.append([t, checkpoint_name2, acc2, epoch_test_loss2, num_correct2, num_wrong2])\n",
    "        print(f'{name2}: Epoch: {t}/{epochs+era2epochs}, Test Loss: {epoch_test_loss2}, Incorrect: {num_wrong2}/1000 examples')\n",
    "        torch.save(model2, f'./models/{checkpoint_name2}')\n",
    "        \n",
    "print(\"END OF ERA 2\")\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a47275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_data1 = pd.DataFrame(full_data1, columns =['epoch', 'training_loss'])\n",
    "df_full_data2 = pd.DataFrame(full_data2, columns =['epoch', 'training_loss'])\n",
    "\n",
    "df_checkpoint_data1 = pd.DataFrame(checkpoint_data1, columns =['epoch', 'checkpoint_name', 'accuracy', 'test_loss', 'num_correct', 'num_wrong'])\n",
    "df_checkpoint_data2 = pd.DataFrame(checkpoint_data2, columns =['epoch', 'checkpoint_name', 'accuracy', 'test_loss', 'num_correct', 'num_wrong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0878f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_data1.to_csv(f'./logs/{name1}_full_data.csv')\n",
    "df_full_data2.to_csv(f'./logs/{name2}_full_data.csv')\n",
    "\n",
    "df_checkpoint_data1.to_csv(f'./logs/{name1}_checkpoint_data.csv')\n",
    "df_checkpoint_data2.to_csv(f'./logs/{name2}_checkpoint_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76941c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gol_venv",
   "language": "python",
   "name": "gol_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
