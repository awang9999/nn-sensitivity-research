{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a064907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from GOLDataset import generateDataset\n",
    "from GOLCNN import OPNet, train_epoch, test_model\n",
    "from MinimalSolution import MinNet\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70df9be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9886d55c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed everything for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbfc8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0, Test Loss: 3.185951683311531e-18, Correct: 1000/1000, Incorrect: 0/1000\n"
     ]
    }
   ],
   "source": [
    "# Ensure test_model() works on the minimal solution CNN\n",
    "dataset_size = 1000\n",
    "dataloader = generateDataset(dataSetSize=dataset_size, size=32, n_steps=3)\n",
    "min_model = MinNet(3)\n",
    "min_model.to(device)\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "acc, epoch_test_loss, num_correct, num_wrong = test_model(min_model, dataloader, 1, criterion)\n",
    "print(f'Accuracy: {acc}, Test Loss: {epoch_test_loss}, Correct: {num_correct}/{dataset_size}, Incorrect: {num_wrong}/{dataset_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3241bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "dataset_size = 1000\n",
    "datapoint_size = 32\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 1e-3\n",
    "batch_size_param = 64\n",
    "epochs = 10\n",
    "checkpoint_rate = 5\n",
    "\n",
    "m = 8 # Overparameterization Factor\n",
    "n = 2  # Steps of GOL simulation\n",
    "\n",
    "model_amber = OPNet(m, n)\n",
    "model_brian = OPNet(m, n)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "optimizer_amber = torch.optim.SGD(model_amber.parameters(), lr=learning_rate)\n",
    "optimizer_brian = torch.optim.SGD(model_brian.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c51e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models loaded to device\n"
     ]
    }
   ],
   "source": [
    "model_amber.to(device)\n",
    "model_brian.to(device)\n",
    "print('models loaded to device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d195285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amber: Epoch: 5/10, Test Loss: 0.24753129482269287, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 5/10, Test Loss: 0.24128539860248566, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 10/10, Test Loss: 0.2460220456123352, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 10/10, Test Loss: 0.24002912640571594, Incorrect: 1000/1000 examples\n",
      "END OF ERA 1\n",
      "Amber: Epoch: 15/20, Test Loss: 0.24586406350135803, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 15/20, Test Loss: 0.239878848195076, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 20/20, Test Loss: 0.24569861590862274, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 20/20, Test Loss: 0.2397150844335556, Incorrect: 1000/1000 examples\n",
      "END OF ERA 2\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "full_data_amber = []\n",
    "full_data_brian = []\n",
    "checkpoint_data_amber = []\n",
    "checkpoint_data_brian = []\n",
    "\n",
    "for t in range(1, epochs + 1):\n",
    "    dataloader = generateDataset(dataSetSize=dataset_size, \n",
    "                                 size=datapoint_size, \n",
    "                                 n_steps=n, \n",
    "                                 batch_size=batch_size_param)\n",
    "    \n",
    "    epoch_train_loss_amber = train_epoch(model_amber, optimizer_amber, criterion, dataloader, m)\n",
    "    full_data_amber.append([t, epoch_train_loss_amber])\n",
    "    \n",
    "    epoch_train_loss_brian = train_epoch(model_brian, optimizer_brian, criterion, dataloader, m)\n",
    "    full_data_brian.append([t, epoch_train_loss_brian])\n",
    "    \n",
    "    if t % checkpoint_rate == 0:\n",
    "        acc_amber, epoch_test_loss_amber, num_correct_amber, num_wrong_amber = test_model(model_amber, dataloader, m, criterion)\n",
    "        checkpoint_name_amber = f'amber_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data_amber.append([t, checkpoint_name_amber, acc_amber, epoch_test_loss_amber, num_correct_amber, num_wrong_amber])\n",
    "        print(f'Amber: Epoch: {t}/{epochs}, Test Loss: {epoch_test_loss_amber}, Incorrect: {num_wrong_amber}/1000 examples')\n",
    "        torch.save(model_amber, f'./models/{checkpoint_name_amber}')\n",
    "        \n",
    "        acc_brian, epoch_test_loss_brian, num_correct_brian, num_wrong_brian = test_model(model_brian, dataloader, m, criterion)\n",
    "        checkpoint_name_brian = f'brian_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data_brian.append([t, checkpoint_name_brian, acc_brian, epoch_test_loss_brian, num_correct_brian, num_wrong_brian])\n",
    "        print(f'Brian: Epoch: {t}/{epochs}, Test Loss: {epoch_test_loss_brian}, Incorrect: {num_wrong_brian}/1000 examples')\n",
    "        torch.save(model_amber, f'./models/{checkpoint_name_brian}')\n",
    "        \n",
    "print(\"END OF ERA 1\")\n",
    "\n",
    "optimizer_amber = torch.optim.SGD(model_amber.parameters(), lr=learning_rate*0.1)\n",
    "optimizer_brian = torch.optim.SGD(model_brian.parameters(), lr=learning_rate*0.1)\n",
    "\n",
    "for t in range(epochs + 1, 2 * epochs + 1):\n",
    "    dataloader = generateDataset(dataSetSize=dataset_size, \n",
    "                                 size=datapoint_size, \n",
    "                                 n_steps=n, \n",
    "                                 batch_size=batch_size_param)\n",
    "    \n",
    "    epoch_train_loss_amber = train_epoch(model_amber, optimizer_amber, criterion, dataloader, m)\n",
    "    full_data_amber.append([t, epoch_train_loss_amber])\n",
    "    \n",
    "    epoch_train_loss_brian = train_epoch(model_brian, optimizer_brian, criterion, dataloader, m)\n",
    "    full_data_brian.append([t, epoch_train_loss_brian])\n",
    "    \n",
    "    if t % checkpoint_rate == 0:\n",
    "        acc_amber, epoch_test_loss_amber, num_correct_amber, num_wrong_amber = test_model(model_amber, dataloader, m, criterion)\n",
    "        checkpoint_name_amber = f'amber_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data_amber.append([t, checkpoint_name_amber, acc_amber, epoch_test_loss_amber, num_correct_amber, num_wrong_amber])\n",
    "        print(f'Amber: Epoch: {t}/{2*epochs}, Test Loss: {epoch_test_loss_amber}, Incorrect: {num_wrong_amber}/1000 examples')\n",
    "        torch.save(model_amber, f'./models/{checkpoint_name_amber}')\n",
    "        \n",
    "        acc_brian, epoch_test_loss_brian, num_correct_brian, num_wrong_brian = test_model(model_brian, dataloader, m, criterion)\n",
    "        checkpoint_name_brian = f'brian_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data_brian.append([t, checkpoint_name_brian, acc_brian, epoch_test_loss_brian, num_correct_brian, num_wrong_brian])\n",
    "        print(f'Brian: Epoch: {t}/{2*epochs}, Test Loss: {epoch_test_loss_brian}, Incorrect: {num_wrong_brian}/1000 examples')\n",
    "        torch.save(model_amber, f'./models/{checkpoint_name_brian}')\n",
    "        \n",
    "print(\"END OF ERA 2\")\n",
    "print(\"DONE!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cd1457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 'amber_m8_n2_checkpoint5.pt', 0.0, 0.2475313, 0, 1000],\n",
       " [10, 'amber_m8_n2_checkpoint10.pt', 0.0, 0.24602205, 0, 1000],\n",
       " [15, 'amber_m8_n2_checkpoint15.pt', 0.0, 0.24586406, 0, 1000],\n",
       " [20, 'amber_m8_n2_checkpoint20.pt', 0.0, 0.24569862, 0, 1000]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_data_amber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a47275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.24893625],\n",
       " [2, 0.24861959],\n",
       " [3, 0.24831773],\n",
       " [4, 0.24800381],\n",
       " [5, 0.24769434],\n",
       " [6, 0.24738495],\n",
       " [7, 0.24708095],\n",
       " [8, 0.24679111],\n",
       " [9, 0.24647474],\n",
       " [10, 0.24618122],\n",
       " [11, 0.24602932],\n",
       " [12, 0.24597196],\n",
       " [13, 0.24594079],\n",
       " [14, 0.24590994],\n",
       " [15, 0.24588001],\n",
       " [16, 0.2458455],\n",
       " [17, 0.24583468],\n",
       " [18, 0.24579148],\n",
       " [19, 0.24577399],\n",
       " [20, 0.24571463]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_amber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "481176c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, f'./models/op_m16_n2_model2.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gol_venv",
   "language": "python",
   "name": "gol_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
