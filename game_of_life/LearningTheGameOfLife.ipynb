{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a064907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from GOLDataset import generateDataset\n",
    "from GOLCNN import OPNet, train_epoch, test_model\n",
    "from MinimalSolution import MinNet\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70df9be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2daff9fc90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed everything for reproducibility\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbfc8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0, Test Loss: 3.1828268017524587e-18, Correct: 1000/1000, Incorrect: 0/1000\n"
     ]
    }
   ],
   "source": [
    "# Ensure test_model() works on the minimal solution CNN\n",
    "dataset_size = 1000\n",
    "dataloader = generateDataset(dataSetSize=dataset_size, size=32, n_steps=3)\n",
    "min_model = MinNet(3)\n",
    "min_model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "acc, epoch_test_loss, num_correct, num_wrong = test_model(min_model, dataloader, 1, criterion)\n",
    "print(f'Accuracy: {acc}, Test Loss: {epoch_test_loss}, Correct: {num_correct}/{dataset_size}, Incorrect: {num_wrong}/{dataset_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3241bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "dataset_size = 1000\n",
    "datapoint_size = 32\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 1e-3\n",
    "batch_size_param = 64\n",
    "epochs = 1500\n",
    "era2epochs = 500\n",
    "checkpoint_rate = 100\n",
    "\n",
    "m = 16 # Overparameterization Factor\n",
    "n = 2  # Steps of GOL simulation\n",
    "\n",
    "model_amber = OPNet(m, n)\n",
    "model_brian = OPNet(m, n)\n",
    "\n",
    "criterion_amber = nn.MSELoss()\n",
    "criterion_brian = nn.MSELoss()\n",
    "optimizer_amber = torch.optim.SGD(model_amber.parameters(), lr=learning_rate)\n",
    "optimizer_brian = torch.optim.SGD(model_brian.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c51e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models loaded to device\n"
     ]
    }
   ],
   "source": [
    "model_amber.to(device)\n",
    "model_brian.to(device)\n",
    "print('models loaded to device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d195285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amber: Epoch: 100/1000, Test Loss: 0.24755781888961792, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 100/1000, Test Loss: 0.22196242213249207, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 200/1000, Test Loss: 0.22412323951721191, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 200/1000, Test Loss: 0.20985013246536255, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 300/1000, Test Loss: 0.21021032333374023, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 300/1000, Test Loss: 0.20256714522838593, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 400/1000, Test Loss: 0.2017800360918045, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 400/1000, Test Loss: 0.19804072380065918, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 500/1000, Test Loss: 0.19629181921482086, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 500/1000, Test Loss: 0.19474750757217407, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 600/1000, Test Loss: 0.19305594265460968, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 600/1000, Test Loss: 0.1927444040775299, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 700/1000, Test Loss: 0.19182661175727844, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 700/1000, Test Loss: 0.1921645998954773, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 800/1000, Test Loss: 0.19085794687271118, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 800/1000, Test Loss: 0.19149434566497803, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 900/1000, Test Loss: 0.18917059898376465, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 900/1000, Test Loss: 0.1899656355381012, Incorrect: 1000/1000 examples\n",
      "Amber: Epoch: 1000/1000, Test Loss: 0.18845514953136444, Incorrect: 1000/1000 examples\n",
      "Brian: Epoch: 1000/1000, Test Loss: 0.18930324912071228, Incorrect: 1000/1000 examples\n",
      "END OF ERA 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m optimizer_brian \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model_brian\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39mera2epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mgenerateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataSetSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatapoint_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     epoch_train_loss_amber \u001b[38;5;241m=\u001b[39m train_epoch(model_amber, optimizer_amber, criterion_amber, dataloader, m)\n\u001b[1;32m     43\u001b[0m     full_data_amber\u001b[38;5;241m.\u001b[39mappend([t, epoch_train_loss_amber])\n",
      "File \u001b[0;32m~/Desktop/everything/projects/nn-sensitivity-research/game_of_life/GOLDataset.py:19\u001b[0m, in \u001b[0;36mgenerateDataset\u001b[0;34m(dataSetSize, size, n_steps, batch_size, returnTensor)\u001b[0m\n\u001b[1;32m     16\u001b[0m inputs\u001b[38;5;241m.\u001b[39mappend(start_state)\n\u001b[1;32m     18\u001b[0m engine\u001b[38;5;241m.\u001b[39mgame_state \u001b[38;5;241m=\u001b[39m start_state\n\u001b[0;32m---> 19\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m output_state \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mgame_state\n\u001b[1;32m     22\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(output_state)\n",
      "File \u001b[0;32m~/Desktop/everything/projects/nn-sensitivity-research/game_of_life/GameOfLife.py:29\u001b[0m, in \u001b[0;36mGameOfLifeEngine.step_n\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, n):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m---> 29\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/everything/projects/nn-sensitivity-research/game_of_life/GameOfLife.py:58\u001b[0m, in \u001b[0;36mStandardEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m live_neighbors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_state[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     57\u001b[0m live_neighbors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_state[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m, j]\n\u001b[0;32m---> 58\u001b[0m live_neighbors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_state[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m, j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m \u001b[38;5;241m<\u001b[39m n \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m live_neighbors \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m: \u001b[38;5;66;03m# dies by underpopulation (rule 1)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     next_state[i,j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_data_amber = []\n",
    "full_data_brian = []\n",
    "checkpoint_data_amber = []\n",
    "checkpoint_data_brian = []\n",
    "\n",
    "for t in range(1, epochs + 1):\n",
    "    dataloader = generateDataset(dataSetSize=dataset_size, \n",
    "                                 size=datapoint_size, \n",
    "                                 n_steps=n, \n",
    "                                 batch_size=batch_size_param)\n",
    "    \n",
    "    epoch_train_loss_amber = train_epoch(model_amber, optimizer_amber, criterion_amber, dataloader, m)\n",
    "    full_data_amber.append([t, epoch_train_loss_amber])\n",
    "    \n",
    "    epoch_train_loss_brian = train_epoch(model_brian, optimizer_brian, criterion_brian, dataloader, m)\n",
    "    full_data_brian.append([t, epoch_train_loss_brian])\n",
    "    \n",
    "    if t % checkpoint_rate == 0:\n",
    "        acc_amber, epoch_test_loss_amber, num_correct_amber, num_wrong_amber = test_model(model_amber, dataloader, m, criterion_amber)\n",
    "        checkpoint_name_amber = f'amber_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data_amber.append([t, checkpoint_name_amber, acc_amber, epoch_test_loss_amber, num_correct_amber, num_wrong_amber])\n",
    "        print(f'Amber: Epoch: {t}/{epochs}, Test Loss: {epoch_test_loss_amber}, Incorrect: {num_wrong_amber}/1000 examples')\n",
    "        torch.save(model_amber, f'./models/{checkpoint_name_amber}')\n",
    "        \n",
    "        acc_brian, epoch_test_loss_brian, num_correct_brian, num_wrong_brian = test_model(model_brian, dataloader, m, criterion_brian)\n",
    "        checkpoint_name_brian = f'brian_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data_brian.append([t, checkpoint_name_brian, acc_brian, epoch_test_loss_brian, num_correct_brian, num_wrong_brian])\n",
    "        print(f'Brian: Epoch: {t}/{epochs}, Test Loss: {epoch_test_loss_brian}, Incorrect: {num_wrong_brian}/1000 examples')\n",
    "        torch.save(model_amber, f'./models/{checkpoint_name_brian}')\n",
    "        \n",
    "print(\"END OF ERA 1\")\n",
    "\n",
    "optimizer_amber = torch.optim.SGD(model_amber.parameters(), lr=learning_rate*0.1)\n",
    "optimizer_brian = torch.optim.SGD(model_brian.parameters(), lr=learning_rate*0.1)\n",
    "\n",
    "for t in range(epochs + 1, epochs+era2epochs+1):\n",
    "    dataloader = generateDataset(dataSetSize=dataset_size, \n",
    "                                 size=datapoint_size, \n",
    "                                 n_steps=n, \n",
    "                                 batch_size=batch_size_param)\n",
    "    \n",
    "    epoch_train_loss_amber = train_epoch(model_amber, optimizer_amber, criterion_amber, dataloader, m)\n",
    "    full_data_amber.append([t, epoch_train_loss_amber])\n",
    "    \n",
    "    epoch_train_loss_brian = train_epoch(model_brian, optimizer_brian, criterion_brian, dataloader, m)\n",
    "    full_data_brian.append([t, epoch_train_loss_brian])\n",
    "    \n",
    "    if t % checkpoint_rate == 0:\n",
    "        acc_amber, epoch_test_loss_amber, num_correct_amber, num_wrong_amber = test_model(model_amber, dataloader, m, criterion_amber)\n",
    "        checkpoint_name_amber = f'amber_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data_amber.append([t, checkpoint_name_amber, acc_amber, epoch_test_loss_amber, num_correct_amber, num_wrong_amber])\n",
    "        print(f'Amber: Epoch: {t}/{epochs+era2epochs}, Test Loss: {epoch_test_loss_amber}, Incorrect: {num_wrong_amber}/1000 examples')\n",
    "        torch.save(model_amber, f'./models/{checkpoint_name_amber}')\n",
    "        \n",
    "        acc_brian, epoch_test_loss_brian, num_correct_brian, num_wrong_brian = test_model(model_brian, dataloader, m, criterion_brian)\n",
    "        checkpoint_name_brian = f'brian_m{m}_n{n}_checkpoint{t}.pt'\n",
    "        checkpoint_data_brian.append([t, checkpoint_name_brian, acc_brian, epoch_test_loss_brian, num_correct_brian, num_wrong_brian])\n",
    "        print(f'Brian: Epoch: {t}/{epochs+era2epochs}, Test Loss: {epoch_test_loss_brian}, Incorrect: {num_wrong_brian}/1000 examples')\n",
    "        torch.save(model_amber, f'./models/{checkpoint_name_brian}')\n",
    "        \n",
    "print(\"END OF ERA 2\")\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a47275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_data_amber = pd.DataFrame(full_data_amber, columns =['epoch', 'training_loss'])\n",
    "df_full_data_brian = pd.DataFrame(full_data_brian, columns =['epoch', 'training_loss'])\n",
    "\n",
    "df_checkpoint_data_amber = pd.DataFrame(checkpoint_data_amber, columns =['epoch', 'checkpoint_name', 'accuracy', 'test_loss', 'num_correct', 'num_wrong'])\n",
    "df_checkpoint_data_brian = pd.DataFrame(checkpoint_data_brian, columns =['epoch', 'checkpoint_name', 'accuracy', 'test_loss', 'num_correct', 'num_wrong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_data_amber.to_csv('./logs/amber_full_data.csv')\n",
    "df_full_data_brian.to_csv('./logs/brian_full_data.csv')\n",
    "\n",
    "df_checkpoint_data_amber.to_csv('./logs/amber_checkpoint_data.csv')\n",
    "df_checkpoint_data_brian.to_csv('./logs/brian_checkpoint_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76941c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gol_venv",
   "language": "python",
   "name": "gol_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
