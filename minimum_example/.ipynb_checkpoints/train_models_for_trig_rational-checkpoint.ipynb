{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6edcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from generic_data import GenericDataset\n",
    "from SimpleNNs import TwoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eacfef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f405c0fc210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f12888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(x):\n",
    "    return np.sin(8 * x) / (4 * np.cos(2 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f8d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range\n",
    "low = -2\n",
    "high = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a52fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training set\n",
    "Xtrain = np.sort(np.random.uniform(low, high, 500))\n",
    "# Xtrain = np.linspace(low, high, 500)\n",
    "np.random.shuffle(Xtrain)\n",
    "Ytrain = target(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e577acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate test set\n",
    "# Xtest = np.sort(np.random.uniform(low, high, 100))\n",
    "# # Xtest = np.linspace(low, high, 100)\n",
    "# Ytest = target(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e5b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GenericDataset(Xtrain.reshape(-1,1), Ytrain.reshape(-1,1))\n",
    "# test_dataset = GenericDataset(Xtest.reshape(-1,1), Ytest.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd508f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "hidden_size = 100\n",
    "shuffle=False\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "lr = 0.1\n",
    "batch_size = 10\n",
    "decreaselr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f1e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TwoNet\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=shuffle)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15a1a294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 0 models\n",
      "Trained 1 models\n",
      "Trained 2 models\n",
      "Trained 3 models\n",
      "Trained 4 models\n",
      "Trained 5 models\n",
      "Trained 6 models\n",
      "Trained 7 models\n",
      "Trained 8 models\n",
      "Trained 9 models\n",
      "Trained 10 models\n",
      "Trained 11 models\n",
      "Trained 12 models\n",
      "Trained 13 models\n",
      "Trained 14 models\n",
      "Trained 15 models\n",
      "Trained 16 models\n",
      "Trained 17 models\n",
      "Trained 18 models\n",
      "Trained 19 models\n",
      "Trained 20 models\n",
      "Trained 21 models\n",
      "Trained 22 models\n",
      "Trained 23 models\n",
      "Trained 24 models\n",
      "Trained 25 models\n",
      "Trained 26 models\n",
      "Trained 27 models\n",
      "Trained 28 models\n",
      "Trained 29 models\n",
      "Trained 30 models\n",
      "Trained 31 models\n",
      "Trained 32 models\n",
      "Trained 33 models\n",
      "Trained 34 models\n",
      "Trained 35 models\n",
      "Trained 36 models\n",
      "Trained 37 models\n",
      "Trained 38 models\n",
      "Trained 39 models\n",
      "Trained 40 models\n",
      "Trained 41 models\n",
      "Trained 42 models\n",
      "Trained 43 models\n",
      "Trained 44 models\n",
      "Trained 45 models\n",
      "Trained 46 models\n",
      "Trained 47 models\n",
      "Trained 48 models\n",
      "Trained 49 models\n",
      "Trained 50 models\n",
      "Trained 51 models\n",
      "Trained 52 models\n",
      "Trained 53 models\n",
      "Trained 54 models\n",
      "Trained 55 models\n",
      "Trained 56 models\n",
      "Trained 57 models\n",
      "Trained 58 models\n",
      "Trained 59 models\n",
      "Trained 60 models\n",
      "Trained 61 models\n",
      "Trained 62 models\n",
      "Trained 63 models\n",
      "Trained 64 models\n",
      "Trained 65 models\n",
      "Trained 66 models\n",
      "Trained 67 models\n",
      "Trained 68 models\n",
      "Trained 69 models\n",
      "Trained 70 models\n",
      "Trained 71 models\n",
      "Trained 72 models\n",
      "Trained 73 models\n",
      "Trained 74 models\n",
      "Trained 75 models\n",
      "Trained 76 models\n",
      "Trained 77 models\n",
      "Trained 78 models\n",
      "Trained 79 models\n",
      "Trained 80 models\n",
      "Trained 81 models\n",
      "Trained 82 models\n",
      "Trained 83 models\n",
      "Trained 84 models\n",
      "Trained 85 models\n",
      "Trained 86 models\n",
      "Trained 87 models\n",
      "Trained 88 models\n",
      "Trained 89 models\n",
      "Trained 90 models\n",
      "Trained 91 models\n",
      "Trained 92 models\n",
      "Trained 93 models\n",
      "Trained 94 models\n",
      "Trained 95 models\n",
      "Trained 96 models\n",
      "Trained 97 models\n",
      "Trained 98 models\n",
      "Trained 99 models\n"
     ]
    }
   ],
   "source": [
    "# Train TwoNet\n",
    "milestones=[75]\n",
    "\n",
    "for i in range (0,100):\n",
    "    model=TwoNet(input_size, output_size, hidden_size)\n",
    "    model = model.double()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if decreaselr and (epoch in milestones):\n",
    "                lr = lr*0.1\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        for x,y in train_loader:          \n",
    "            #make a prediction\n",
    "            yhat=model(x)\n",
    "            #calculate the loss\n",
    "            loss=criterion(yhat,y)\n",
    "            #clear gradient \n",
    "            optimizer.zero_grad()\n",
    "            #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "            loss.backward()\n",
    "            #the step function on an Optimizer makes an update to its parameters\n",
    "            optimizer.step()\n",
    "    \n",
    "    torch.save(model, f'./models/random_init/model_{i:02d}.pt')\n",
    "    print(f'Trained {i} models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57336d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=shuffle)\n",
    "\n",
    "# preds = []\n",
    "# labels = []\n",
    "    \n",
    "# for batch_vec, batch_labels in iter(test_loader):\n",
    "#     batch_outputs = model(batch_vec)\n",
    "#     batch_preds = batch_outputs.cpu().detach().numpy()\n",
    "#     batch_labels = batch_labels.numpy()\n",
    "#     preds.append(batch_preds)\n",
    "#     labels.append(batch_labels)\n",
    "\n",
    "# preds = np.concatenate(preds)\n",
    "# labels = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute regression error\n",
    "# regression_error = np.square(np.subtract(preds, labels)).mean()\n",
    "# regression_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.scatter(Xtest, preds, label='pred', s=5)\n",
    "# ax.scatter(Xtest, Ytest, label='true', s=5)\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87862e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Residual plot\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.plot(Xtest, np.abs(preds - Ytest.reshape(-1,1)), label='resid')\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafda401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
